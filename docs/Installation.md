## Installation
GNN-RL is tested under the the following environment and dependencies:
***
**Python       >=3.6**  
**PyTorch      1.9.1 (CUDA 11.1)**  
**CUDA Toolkit 11.1**
***
GNN-RL supports multiple Graph libraries as backends, e.g., DGL, PyG.   
***
[**DGL (with CUDA 11.1)**](https://www.dgl.ai/pages/start.html)   
[**PyG (torch-geometric)**](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html#) 
***


## GNN-RL installation from pip
Before installing the GNN-RL, installing the required PyTorch through pip,
```bash
pip install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html
```
installing the required Graph libraries,
```bash
pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.9.0+cu111.html
pip install dgl-cu111 -f https://data.dgl.ai/wheels/repo.html
```
Install the gnnrl,
```bash
pip install gnnrl
```

## GNN-RL installation from conda
Will release soon




[comment]: <> (Pip)

[comment]: <> (python=3.7)

[comment]: <> (PyTorch 1.10.1 with CUDA 10.2)

[comment]: <> (```bash)

[comment]: <> (conda install pytorch==1.9.1 torchvision==0.10.1 torchaudio==0.9.1 cudatoolkit=11.1 -c pytorch -c conda-forge)

[comment]: <> (pip install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html)

[comment]: <> (```)

[comment]: <> (conda install pytorch==1.9.1 torchvision==0.10.1 torchaudio==0.9.1 cudatoolkit=11.1 -c pytorch -c conda-forge)

[comment]: <> (pip install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html)

[comment]: <> (conda install pyg -c pyg -c conda-forge)

[comment]: <> (pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.9.0+cu111.html)


[comment]: <> (conda install -c dglteam dgl-cuda11.1)

[comment]: <> (pip install dgl-cu111 -f https://data.dgl.ai/wheels/repo.html)

[comment]: <> (Will release soon)

[comment]: <> (export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/work/LAS/jannesar-lab/yusx/anaconda3/lib/)

[comment]: <> (## Install from pip)

<!-- 
Currently we support installation on Linux, Mac and Windows. We also allow you to use docker.

DGL works with the following operating systems:

Ubuntu 16.04

macOS X

Windows 10

DGL requires Python version 3.6, 3.7, 3.8 or 3.9.

DGL supports multiple tensor libraries as backends, e.g., PyTorch, MXNet. For requirements on backends and how to select one, see Working with different backends.

Starting at version 0.3, DGL is separated into CPU and CUDA builds. The builds share the same Python package name. If you install DGL with a CUDA 9 build after you install the CPU build, then the CPU build is overwritten.



## Install by Conda


Lorem markdownum Pyrrhus piscosamque? Sis Caras clamant **duorum**, somnia
comitant, solvit, quos secum. Dato ipse Pergama ulla, accedere abigitque
**aper**. Haec socero quoque ibi, cremarat atque amo qui tetigere crine,
temptanti.

- A cunctisque amens
- Sospes genuumque pereat
- Corpusque nam obice nec suis receptus Athos
- Quam accipe raptam

Diuque ut Perseia fabula foedantem quondam. Non sub simulatoremque iuvenci.

    if (enterpriseForumBitrate - fiDot <= simmModel) {
        ctr(ajaxRupHttps, mouse(technologyPppoe, reciprocal_servlet),
                services_image_adc);
        rightGopherApple += hover_desktop_adc.processFriendly(-3, compression,
                scrollBootProtector);
        clone_integrated(-5);
    } else {
        olePci(ergonomics_sli, urlReal, coreCpaGamma);
        barcraftReimageCursor = applet - 4 + samplingPrinter;
        maximize(uat_gate - terminalUnfriendSip, hyperlinkDaemonIm(handle_drag,
                third, lifo), prebindingClient);
    }
    var rosetta_secondary_affiliate = firewire;
    rjBus = 331673;

## Install from Pip

Orbem minacia turba minanti [afflatibus](http://simuldicitur.org/quoque.html)
tremulo **iussit**, ab arsit relinquunt, poplite superos. Amplexumque retenta
radice per Ityn est positos vulnus; *quae* anima ab inpulsu minores; ferenda
[nec](http://egonostra.io/satavidamque.aspx) tellure. Labor momentaque Herculeae
potiunda a **neque sanguine**, non quod defensae. Non mandata vinclo?

    home.dvdPayloadHard += property_uml(barDirectMinimize);
    if (4 + control > switch(shell)) {
        terminalItunes.biometricsRemoteServer = pipeline_speed_click;
        view_vector += web;
    }
    menuRoomCut -= core_postscript_direct + processorPc + drop_kindle;

Dedecus haec; hic et recuset mens totidem inque, ut et quid capillis, ego erit
alendum. Evehor cum color, vulnere, ipsaque non ponto, est acrior inmitis quae
tinxi, ab.

## Install from Source Code
Invitus uvis preces mihi? Quam etiam en utque; alit et pro induroque dare
profecturas iuvenum sollertia reperta resedit et traiecit gaude. Et non nymphae
**utero temerarius cernit** egimus omnipotens hos, terrae, captum sanguine per;
hiatu. -->
